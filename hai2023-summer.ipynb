{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# 입력된 발화의 지역 방언을 구분하는 모델 학습시키기\n\n- 입력된 텍스트가 표준어 발화인지 아니면 특정 지역의 방언인지 분류할 수 있는 모델을 학습시켜 봅시다.\n- 먼저 필요한 라이브러리를 설치 및 import해 줍니다.","metadata":{"id":"rxoBTI7SCcWm"}},{"cell_type":"code","source":"!pip install transformers easydict keras_preprocessing --quiet\n\nimport os\nimport random\nimport easydict\nimport requests\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom tqdm import tqdm\nfrom transformers import AdamW, get_linear_schedule_with_warmup\nfrom torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\nfrom keras_preprocessing.sequence import pad_sequences\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"id":"yzHvV4HlGw4r","outputId":"b70e57dc-c019-45ea-a800-e93a2cb2cb7f","execution":{"iopub.status.busy":"2023-08-16T03:48:44.088928Z","iopub.execute_input":"2023-08-16T03:48:44.089417Z","iopub.status.idle":"2023-08-16T03:48:55.586522Z","shell.execute_reply.started":"2023-08-16T03:48:44.089384Z","shell.execute_reply":"2023-08-16T03:48:55.585179Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"markdown","source":"- 다음은 학습 과정에서 데이터의 전처리와 배치 단위 입력을 수월하게 처리해줄 수 있게 하는 DataLoader를 이용하여 모델 학습을 위한 데이터를 전처리하는 함수입니다.\n- generate_data_loader를 호출하면 입력된 파일 경로에서 파일을 읽어와 적절한 토크나이징을 진행하고 args에 정의되어 있는 크기만큼 배치 단위로 데이터를 제공할 수 있는 iteratable한 DataLoader 객체를 반환하게 됩니다.","metadata":{"id":"sBSOt-66CcWq"}},{"cell_type":"code","source":"def generate_data_loader(file_path, tokenizer, args):\n    def get_input_ids(data):\n        document_bert = [\"[CLS] \" + str(s) + \" [SEP]\" for s in data]\n        tokenized_texts = [tokenizer.tokenize(s) for s in tqdm(document_bert, \"Tokenizing\")]\n        input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts, \"Converting tokens to ids\")]\n        print(\"Padding sequences...\")\n        input_ids = pad_sequences(input_ids, maxlen=args.maxlen, dtype='long', truncating='post', padding='post')\n        return input_ids\n\n    def get_attention_masks(input_ids):\n        attention_masks = []\n        for seq in tqdm(input_ids, \"Generating attention masks\"):\n            seq_mask = [float(i > 0) for i in seq]\n            attention_masks.append(seq_mask)\n        return attention_masks\n\n    def get_data_loader(inputs, masks, labels, batch_size=args.batch):\n        data = TensorDataset(torch.tensor(inputs), torch.tensor(masks), torch.tensor(labels))\n        sampler = RandomSampler(data) if args.mode == 'train' else SequentialSampler(data)\n        data_loader = DataLoader(data, sampler=sampler, batch_size=batch_size)\n        return data_loader\n\n    data_df = pd.read_csv(file_path)\n    input_ids = get_input_ids(data_df['text'].values)\n    attention_masks = get_attention_masks(input_ids)\n    data_loader = get_data_loader(input_ids, attention_masks, data_df['label'].values if args.mode=='train' else [-1]*len(data_df))\n\n    return data_loader","metadata":{"id":"G8mG8ElvGw4t","execution":{"iopub.status.busy":"2023-08-16T03:48:55.589684Z","iopub.execute_input":"2023-08-16T03:48:55.590090Z","iopub.status.idle":"2023-08-16T03:48:55.601986Z","shell.execute_reply.started":"2023-08-16T03:48:55.590051Z","shell.execute_reply":"2023-08-16T03:48:55.600945Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"markdown","source":"- 아래 함수는 모델을 학습/추론하는 과정에서 필요한 보조 함수들입니다.\n- save는 torch 라이브러리의 state_dict를 저장하는 기능을 이용해 모델의 가중치만 주어진 경로에 저장하는 함수입니다.\n- flat_accuracy는 모델이 예측한 결과값과 정답 라벨을 비교하여 얼마나 정확하게 맞혔는지 정확도를 구해주는 함수입니다.","metadata":{"id":"98fSFgXPCcWs"}},{"cell_type":"code","source":"def save(model, dir_name):\n    os.makedirs(dir_name, exist_ok=True)\n    torch.save(model.state_dict(), os.path.join(dir_name, 'model.pth'))\n\ndef flat_accuracy(preds, labels):\n    pred_flat = np.argmax(preds, axis=1).flatten()\n    labels_flat = labels.flatten()\n    return np.sum(pred_flat == labels_flat) / len(labels_flat)","metadata":{"id":"TfO9ISW2Gw4u","execution":{"iopub.status.busy":"2023-08-16T03:48:55.603501Z","iopub.execute_input":"2023-08-16T03:48:55.603905Z","iopub.status.idle":"2023-08-16T03:48:55.614133Z","shell.execute_reply.started":"2023-08-16T03:48:55.603871Z","shell.execute_reply":"2023-08-16T03:48:55.613028Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"- predict는 학습된 모델을 평가하기 위한 함수입니다. 데이터 입력을 DataLoader 형식으로 받아 모델이 예측한 값을 받아온 뒤 flat_accuracy를 호출하여 정답 라벨과 비교한 정확도를 계산합니다.\n- 모델의 추론 과정(Validation 또는 Test 과정)에서 back propagation은 일어나지 않기 때문에, 계산 속도를 높이기 위해 torch.no_grad()를 실행하여 모델에 데이터를 입력해도 gradient가 따로 계산되어 저장되지 않도록 했습니다.","metadata":{"id":"19xHdV2yCcWt"}},{"cell_type":"code","source":"def predict(model, args, data_loader):\n    print('start predict')\n    model.eval()\n\n    eval_accuracy = []\n    logits = []\n\n    for step, batch in tqdm(enumerate(data_loader)):\n        batch = tuple(t.to(args.device) for t in batch)\n        b_input_ids, b_input_mask, b_labels = batch\n        with torch.no_grad():\n            outputs = model(b_input_ids,\n                            attention_mask=b_input_mask)\n        logit = outputs[0]\n\n        logit = logit.detach().cpu().numpy()\n        label = b_labels.cpu().numpy()\n\n        logits.append(logit)\n\n        accuracy = flat_accuracy(logit, label)\n        eval_accuracy.append(accuracy)\n\n    logits = np.vstack(logits)\n    predict_labels = np.argmax(logits, axis=1)\n    return predict_labels, np.mean(eval_accuracy)","metadata":{"id":"wqQfejZyGw4u","execution":{"iopub.status.busy":"2023-08-16T03:48:55.618319Z","iopub.execute_input":"2023-08-16T03:48:55.618605Z","iopub.status.idle":"2023-08-16T03:48:55.628404Z","shell.execute_reply.started":"2023-08-16T03:48:55.618580Z","shell.execute_reply":"2023-08-16T03:48:55.627523Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"markdown","source":"- 이 노트북에서 가장 중요한 부분인 train은 모델을 학습시키기 위한 함수입니다. Train data와 Valid data를 각각 DataLoader 형태로 입력받아 학습과 검증 과정을 거치게 됩니다.\n- 개선된 optimization 알고리즘인 AdamW와 learning rate를 선형적으로 감소시키는 linear scheduler를 이용하여 학습을 진행합니다.\n- 한 epoch가 종료되면 valid_loader를 이용해 predict를 호출하여 validation accuracy를 계산합니다.\n- 대부분의 PyTorch를 활용한 모델 학습 과정은 이 함수와 비슷한 과정을 거쳐 진행되니 패턴에 익숙해지면 좋습니다.","metadata":{"id":"eRlgMVV-CcWu"}},{"cell_type":"code","source":"def train(model, args, train_loader, valid_loader):\n    optimizer = AdamW(model.parameters(),\n                      lr=args.lr,\n                      eps=args.eps\n                      )\n    total_steps = len(train_loader) * args.epochs\n\n    scheduler = get_linear_schedule_with_warmup(optimizer,\n                                                num_warmup_steps=0,\n                                                num_training_steps=total_steps)\n\n    seed_val = 42\n    random.seed(seed_val)\n    np.random.seed(seed_val)\n    torch.manual_seed(seed_val)\n    torch.cuda.manual_seed_all(seed_val)\n\n    print('start training')\n    for epoch in range(args.epochs):\n        model.train()\n        train_loss = []\n        for step, batch in tqdm(enumerate(train_loader), f\"training epoch {epoch}\", total=len(train_loader)):\n            model.zero_grad()\n            batch = tuple(t.to(args.device) for t in batch)\n            b_input_ids, b_input_mask, b_labels = batch\n            outputs = model(b_input_ids,\n                            attention_mask=b_input_mask,\n                            labels=b_labels)\n            loss = outputs[0]\n            train_loss.append(loss.item())\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n            optimizer.step()\n            scheduler.step()\n\n        avg_train_loss = np.mean(train_loss)\n        _, avg_train_accuracy = predict(model, args, train_loader)\n        _, avg_val_accuracy = predict(model, args, valid_loader)\n        print(\"Epoch {0},  Average training loss: {1:.4f} , Train accuracy : {2:.4f}, Validation accuracy : {3:.4f}\"\\\n              .format(epoch, avg_train_loss, avg_train_accuracy, avg_val_accuracy))\n\n        save(model, \"./saved_checkpoints/\" + str(epoch))\n    return model","metadata":{"id":"twbi-hjmGw4v","execution":{"iopub.status.busy":"2023-08-16T03:48:55.629963Z","iopub.execute_input":"2023-08-16T03:48:55.630415Z","iopub.status.idle":"2023-08-16T03:48:55.643958Z","shell.execute_reply.started":"2023-08-16T03:48:55.630383Z","shell.execute_reply":"2023-08-16T03:48:55.642977Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"markdown","source":"- 필요한 함수를 정의 완료했으니 학습을 본격적으로 진행해 봅시다.\n- args에는 학습 과정에서 지정해야 할 각종 하이퍼파라미터(배치 사이즈, learning rate 등등)와 데이터 파일 경로 등을 입력해둬 코드 실행 과정에서 사용할 수 있도록 합니다.","metadata":{"id":"eQ94RwlbCcWv"}},{"cell_type":"code","source":"args = easydict.EasyDict({\n  \"train_path\" : \"./data/train.csv\",\n  \"valid_path\" : \"./data/valid.csv\",\n  \"device\" : 'cpu',\n  \"mode\" : \"train\",\n  \"batch\" : 128,\n  \"maxlen\" : 128,\n  \"lr\" : 35e-6,\n  \"eps\" : 1e-8,\n  \"epochs\" : 1,\n  \"model_ckpt\" : \"kykim/bert-kor-base\",\n})\n\nif torch.cuda.is_available():\n    args.device = 'cuda'","metadata":{"id":"soqhgEExGw4w","execution":{"iopub.status.busy":"2023-08-16T03:48:55.645488Z","iopub.execute_input":"2023-08-16T03:48:55.645839Z","iopub.status.idle":"2023-08-16T03:48:55.658599Z","shell.execute_reply.started":"2023-08-16T03:48:55.645808Z","shell.execute_reply":"2023-08-16T03:48:55.657505Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"markdown","source":"- 전처리가 완료된 데이터는 kaggle competition의 Data 페이지에서 다운로드받을 수 있습니다.\n- 다운로드받은 데이터 파일을 압축 해제해서 `data` 디렉토리에 옮겨 주세요.\n- kaggle notebook을 사용중인 경우 이미 데이터가 다운로드되어 있으니 바로 사용하면 됩니다.","metadata":{"id":"iQakEB52CcWv"}},{"cell_type":"code","source":"# 현재 디렉토리 내부 data 폴더에 데이터 파일을 다운로드받아 압축을 해제해 주세요.\nos.makedirs('./data', exist_ok=True)\n\n# kaggle competition에서 제공하는 notebook을 사용 중인 경우\n!cp /kaggle/input/hai2023summer/* ./data\n\n# 데이터 다운로드 링크\n# https://www.kaggle.com/competitions/hai2023summer/data","metadata":{"id":"TOPktFqTJu-m","outputId":"10c1823c-553e-468f-f7ac-c27679514c2e","execution":{"iopub.status.busy":"2023-08-16T03:48:55.660298Z","iopub.execute_input":"2023-08-16T03:48:55.660736Z","iopub.status.idle":"2023-08-16T03:48:56.710327Z","shell.execute_reply.started":"2023-08-16T03:48:55.660703Z","shell.execute_reply":"2023-08-16T03:48:56.709024Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"markdown","source":"- Train/Valid 데이터는 각각 idx, text, label 세 개의 column을 가지는 csv 파일 형태로 이루어져 있습니다. text는 평가 대상 발화 텍스트가, label은 방언 여부를 나타내는 정수 라벨입니다(표준어일 경우 0, 경상도 방언일 경우 1, 제주도 방언일 경우 2).","metadata":{"id":"hlCscJoxCcWw"}},{"cell_type":"code","source":"train_data_df = pd.read_csv(args.train_path)\nprint(train_data_df.head())\nprint(train_data_df.tail())","metadata":{"id":"Fj1jfARMCcWw","outputId":"07eabadd-cfb2-45ba-b945-79f016df9172","execution":{"iopub.status.busy":"2023-08-16T03:48:56.712703Z","iopub.execute_input":"2023-08-16T03:48:56.713193Z","iopub.status.idle":"2023-08-16T03:48:57.103978Z","shell.execute_reply.started":"2023-08-16T03:48:56.713136Z","shell.execute_reply":"2023-08-16T03:48:57.102840Z"},"trusted":true},"execution_count":35,"outputs":[{"name":"stdout","text":"   idx                                               text  label\n0    0                                   어 뭐라하지 엄청 정들이 많아      0\n1    1                  대개 보니까 엄마 나이가 돼서 아프시니까 허리 수술을 이렇게      0\n2    2                     에피소드라면 일단은 버스가 네가 알다시피 되게 크잖아.      0\n3    3  무신 죽었져 어쩌게 기저 질환이 이신 사람들이 그렇게 했겠지만은 맹심향 좀 몸이 이...      2\n4    4  그 쌤이 처음에 다른 샘들한테 내 욕을 하는 걸 내가 건너서 들었는데 나중에는 제일...      0\n           idx                                               text  label\n190735  190735                                     아이들양 간식을 메길거난.      2\n190736  190736                                               그니까요      0\n190737  190737  아~ 뭐~ 올래도 갑자기 올래는 이상하게 십일월 달인가 되게 안 추웠잖아요 십일월 ...      1\n190738  190738                      다 나왔잖아 치얼업이랑 티티랑 그때 노래가 너무 좋아      0\n190739  190739         고양이상인 사람은 예쁜데 고양이를 보면서 막 이러진 않아 막 너는 막 이렇게      0\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 이제 학습을 위한 모델을 준비해 보겠습니다.\n- args에 정의되어 있는 모델의 체크포인트를 이용해 Huggingface hub로부터 sequence classification을 위한 모델과 토크나이저를 불러온 뒤, 모델을 GPU 메모리로 옮깁니다.\n- 분류해야 하는 class의 종류가 3가지(표준어, 경상도, 제주도)이기 때문에, num_labels를 3으로 지정해 주었습니다.","metadata":{"id":"ScKz85rzCcWw"}},{"cell_type":"code","source":"# load model and tokenizer\n# CHECKPOINT_NAME = 'kykim/bert-kor-base'\nmodel = BertForSequenceClassification.from_pretrained(args.model_ckpt, num_labels=3)\nmodel.to(args.device)\ntokenizer = BertTokenizer.from_pretrained(args.model_ckpt)","metadata":{"id":"iy2KULr5J6mE","outputId":"56ee358f-e138-4d9f-cede-5ed8686b3d8b","execution":{"iopub.status.busy":"2023-08-16T03:48:57.105433Z","iopub.execute_input":"2023-08-16T03:48:57.105900Z","iopub.status.idle":"2023-08-16T03:48:58.968873Z","shell.execute_reply.started":"2023-08-16T03:48:57.105863Z","shell.execute_reply":"2023-08-16T03:48:58.967884Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stderr","text":"Some weights of the model checkpoint at kykim/bert-kor-base were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.decoder.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at kykim/bert-kor-base and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 미리 정의된 generate_data_loader 함수를 이용해 train/valid 데이터에 대한 DataLoader를 생성합니다.","metadata":{"id":"VGFn0menCcWx"}},{"cell_type":"code","source":"train_dataloader = generate_data_loader(args.train_path, tokenizer, args)\nvalidation_dataloader = generate_data_loader(args.valid_path, tokenizer, args)","metadata":{"id":"xMAhDeUlJ7-6","outputId":"9212cc75-7047-4881-d4a7-59ace55b75bb","execution":{"iopub.status.busy":"2023-08-16T03:48:58.972395Z","iopub.execute_input":"2023-08-16T03:48:58.972981Z","iopub.status.idle":"2023-08-16T03:50:19.551997Z","shell.execute_reply.started":"2023-08-16T03:48:58.972944Z","shell.execute_reply":"2023-08-16T03:50:19.550751Z"},"trusted":true},"execution_count":37,"outputs":[{"name":"stderr","text":"Tokenizing: 100%|██████████| 190740/190740 [00:51<00:00, 3710.57it/s]\nConverting tokens to ids: 100%|██████████| 190740/190740 [00:03<00:00, 52984.09it/s]\n","output_type":"stream"},{"name":"stdout","text":"Padding sequences...\n","output_type":"stream"},{"name":"stderr","text":"Generating attention masks: 100%|██████████| 190740/190740 [00:16<00:00, 11363.70it/s]\nTokenizing: 100%|██████████| 973/973 [00:00<00:00, 3871.25it/s]\nConverting tokens to ids: 100%|██████████| 973/973 [00:00<00:00, 60077.40it/s]\n","output_type":"stream"},{"name":"stdout","text":"Padding sequences...\n","output_type":"stream"},{"name":"stderr","text":"Generating attention masks: 100%|██████████| 973/973 [00:00<00:00, 12392.83it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 모델과 하이퍼파라미터 그리고 데이터가 준비되었으니 학습을 진행시켜 봅시다.\n- 각 epoch가 끝날 때 마다 모델의 가중치를 저장하고 validation 결과를 출력합니다. 이를 바탕으로 최적의 결과를 가지는 모델을 선택할 수 있습니다.","metadata":{"id":"UEAt94NRCcWx"}},{"cell_type":"code","source":"model = train(model, args, train_dataloader, validation_dataloader)","metadata":{"id":"p7oAiNWVPDYJ","outputId":"e121e329-1fdf-41fa-fbfe-89986fb11dcb","execution":{"iopub.status.busy":"2023-08-16T03:50:19.554701Z","iopub.execute_input":"2023-08-16T03:50:19.555063Z","iopub.status.idle":"2023-08-16T04:36:00.026974Z","shell.execute_reply.started":"2023-08-16T03:50:19.555035Z","shell.execute_reply":"2023-08-16T04:36:00.025576Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"start training\n","output_type":"stream"},{"name":"stderr","text":"training epoch 0: 100%|██████████| 1491/1491 [33:54<00:00,  1.36s/it]\n","output_type":"stream"},{"name":"stdout","text":"start predict\n","output_type":"stream"},{"name":"stderr","text":"1491it [11:41,  2.13it/s]\n","output_type":"stream"},{"name":"stdout","text":"start predict\n","output_type":"stream"},{"name":"stderr","text":"8it [00:03,  2.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 0,  Average training loss: 0.2478 , Train accuracy : 0.9475, Validation accuracy : 0.9300\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 학습이 완료된 모델을 활용하여 test 데이터셋에 대한 추론을 진행해 보겠습니다.\n- 평가를 위해서는 데이터의 각 인덱스에 맞춰 라벨을 예측하는 것이 필요하기 때문에, 새로운 argument를 정의해 사용하겠습니다.","metadata":{}},{"cell_type":"code","source":"test_args = easydict.EasyDict({\n  \"device\" : \"cpu\",\n  \"mode\" : \"test\",\n  \"batch\" : 128,\n  \"maxlen\" : 128,\n})\n\nif torch.cuda.is_available():\n    test_args.device = 'cuda'\n\ntest_dataloader = generate_data_loader(\"data/test.csv\", tokenizer=tokenizer, args=test_args)\nlabels, _ = predict(model, test_args, test_dataloader)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T04:36:00.033621Z","iopub.execute_input":"2023-08-16T04:36:00.036593Z","iopub.status.idle":"2023-08-16T04:36:02.684259Z","shell.execute_reply.started":"2023-08-16T04:36:00.036547Z","shell.execute_reply":"2023-08-16T04:36:02.683238Z"},"trusted":true},"execution_count":39,"outputs":[{"name":"stderr","text":"Tokenizing: 100%|██████████| 626/626 [00:00<00:00, 2731.52it/s]\nConverting tokens to ids: 100%|██████████| 626/626 [00:00<00:00, 53467.62it/s]\n","output_type":"stream"},{"name":"stdout","text":"Padding sequences...\n","output_type":"stream"},{"name":"stderr","text":"Generating attention masks: 100%|██████████| 626/626 [00:00<00:00, 12030.84it/s]\n","output_type":"stream"},{"name":"stdout","text":"start predict\n","output_type":"stream"},{"name":"stderr","text":"5it [00:02,  2.18it/s]\n","output_type":"stream"}]},{"cell_type":"markdown","source":"- 추론 결과는 데이터의 인덱스와 합쳐 제출 파일 형식에 맞게 저장합니다.\n- kaggle competition 페이지에서 submit prediction 메뉴를 활용해 예측 결과에 대한 평가를 확인할 수 있습니다.","metadata":{}},{"cell_type":"code","source":"submit_df = pd.DataFrame()\nsubmit_df[\"idx\"] = range(len(labels))\nsubmit_df[\"label\"] = labels\nsubmit_df.to_csv(\"submission.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2023-08-16T04:36:02.685693Z","iopub.execute_input":"2023-08-16T04:36:02.686422Z","iopub.status.idle":"2023-08-16T04:36:02.698112Z","shell.execute_reply.started":"2023-08-16T04:36:02.686385Z","shell.execute_reply":"2023-08-16T04:36:02.696972Z"},"trusted":true},"execution_count":40,"outputs":[]}]}